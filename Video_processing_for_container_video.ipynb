{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e15e31a9-6043-4799-9cda-513694964b2b",
   "metadata": {},
   "source": [
    "# Here are some Pre processing steps \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8770a5e-4089-4a3b-80cb-5a65e806e3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Base_YOLOV7-Object-of-interest.ipynb\n",
      " Base_YOLOV7.ipynb\n",
      " LICENSE\n",
      "'Sample warehouse CCTV video.mp4'\n",
      " Untitled.ipynb\n",
      " Video_processing.ipynb\n",
      " Video_processing_base.ipynb\n",
      " pytorch-helmet-detection-fasterrcnn.ipynb\n",
      " untitled.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50da60a2-eec6-4d5a-a40d-f85df104d69a",
   "metadata": {},
   "source": [
    "# Step 1 is to down load the Video From GCP to This notebook here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf416b32-695e-44e2-a7a9-6bf16d5613e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 0: syntax error near unexpected token `('\n",
      "/bin/bash: -c: line 0: `gsutil cp gs://my-project-0004-bucket02/experiments/Sample warehouse CCTV video (2).mp4  ./'\n"
     ]
    }
   ],
   "source": [
    "### Lets say our video is present here\n",
    "## dir = gs://my-project-0004-bucket02/experiments/Sample warehouse CCTV video (2).mp4 \n",
    "\n",
    "\n",
    "!gsutil cp gs://my-project-0004-bucket02/experiments/Sample warehouse CCTV video (2).mp4  ./\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cae2fc-6de3-4303-86ec-cbea6cf542ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Changing frame rates as we may not need a very high frame Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e5c3990-3f0c-459c-ae3c-4ce9c7310f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ffmpeg -i Sample_video_fps.mp4 \n",
    "# -- USE THIS code to Get all video details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194f1ac-a87e-4eab-a31b-10d390083adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -y -r 30 -i Sample_video.mp4 -r 1 Sample_video_fps.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6122d20-a084-4053-974e-326bfd6440b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate way could be to lower down the Frame rate  \n",
    "# !ffmpeg -i Sample_video.mp4 -filter:v fps=fps=2 Sample_video_fps2.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71ee88e2-ee18-40ee-b039-d1fe29af32b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.1.10-0+deb10u1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 8 (Debian 8.3.0-6)\n",
      "  configuration: --prefix=/usr --extra-version=0+deb10u1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 22.100 / 56. 22.100\n",
      "  libavcodec     58. 35.100 / 58. 35.100\n",
      "  libavformat    58. 20.100 / 58. 20.100\n",
      "  libavdevice    58.  5.100 / 58.  5.100\n",
      "  libavfilter     7. 40.101 /  7. 40.101\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  3.100 /  5.  3.100\n",
      "  libswresample   3.  3.100 /  3.  3.100\n",
      "  libpostproc    55.  3.100 / 55.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'Sample_video_fps.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.20.100\n",
      "    comment         : Create videos with https://clipchamp.com/en/video-editor - free online video editor, video compressor, video converter.\n",
      "  Duration: 00:59:29.50, start: 0.000000, bitrate: 780 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1920x1080, 775 kb/s, 2 fps, 2 tbr, 16384 tbn, 4 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 2 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "\u001b[4;31mAt least one output file must be specified\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "### Get details about the final video thats produced\n",
    "\n",
    "!ffmpeg -i Sample_video_fps.mp4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de173771-5b73-4f26-800a-9ad11ee7d372",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Split video into multiple videos \n",
    "## Bard Suggest to use --- \n",
    "#### Using this Code it works https://blog.programster.org/ffmpeg-split-video-into-chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66b26b65-0eaa-4adc-a912-518e6eb11a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Final videos into chunks - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18eb7d2f-b8e9-4acf-abf4-e6b0af9da357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.1.10-0+deb10u1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 8 (Debian 8.3.0-6)\n",
      "  configuration: --prefix=/usr --extra-version=0+deb10u1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 22.100 / 56. 22.100\n",
      "  libavcodec     58. 35.100 / 58. 35.100\n",
      "  libavformat    58. 20.100 / 58. 20.100\n",
      "  libavdevice    58.  5.100 / 58.  5.100\n",
      "  libavfilter     7. 40.101 /  7. 40.101\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  3.100 /  5.  3.100\n",
      "  libswresample   3.  3.100 /  3.  3.100\n",
      "  libpostproc    55.  3.100 / 55.  3.100\n",
      "\u001b[0;35m[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5635c7c9c900] \u001b[0m\u001b[1;31mmoov atom not found\n",
      "\u001b[0m\u001b[1;31m./Sample warehouse CCTV video.mp4: Invalid data found when processing input\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!ffmpeg \\\n",
    "  -i ./Sample_video_fps.mp4 \\\n",
    "  -c copy \\\n",
    "  -map 0 \\\n",
    "  -segment_time 00:10:00 \\\n",
    "  -f segment \\\n",
    "  -reset_timestamps 1 \\\n",
    "  output_fps%03d.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02a56f0c-5286-404c-b4c3-e371a671da03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.1.10-0+deb10u1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 8 (Debian 8.3.0-6)\n",
      "  configuration: --prefix=/usr --extra-version=0+deb10u1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 22.100 / 56. 22.100\n",
      "  libavcodec     58. 35.100 / 58. 35.100\n",
      "  libavformat    58. 20.100 / 58. 20.100\n",
      "  libavdevice    58.  5.100 / 58.  5.100\n",
      "  libavfilter     7. 40.101 /  7. 40.101\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  3.100 /  5.  3.100\n",
      "  libswresample   3.  3.100 /  3.  3.100\n",
      "  libpostproc    55.  3.100 / 55.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'Sample_video_fps2.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.20.100\n",
      "    comment         : Create videos with https://clipchamp.com/en/video-editor - free online video editor, video compressor, video converter.\n",
      "  Duration: 00:59:28.68, start: 0.000000, bitrate: 780 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1920x1080, 775 kb/s, 2 fps, 2 tbr, 16384 tbn, 4 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 2 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "\u001b[4;31mAt least one output file must be specified\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i Sample_video_fps2.mp4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c87d123-3220-4905-bdf1-b69f20074468",
   "metadata": {},
   "source": [
    "# Add the code to convert Video to Images with nameing convertion of seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ede2f6e-adb4-4e78-a607-d6f056ff6a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/video_analytics\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e39a2220-8a88-4cb6-85ed-3630898cefed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.1.10-0+deb10u1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 8 (Debian 8.3.0-6)\n",
      "  configuration: --prefix=/usr --extra-version=0+deb10u1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 22.100 / 56. 22.100\n",
      "  libavcodec     58. 35.100 / 58. 35.100\n",
      "  libavformat    58. 20.100 / 58. 20.100\n",
      "  libavdevice    58.  5.100 / 58.  5.100\n",
      "  libavfilter     7. 40.101 /  7. 40.101\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  3.100 /  5.  3.100\n",
      "  libswresample   3.  3.100 /  3.  3.100\n",
      "  libpostproc    55.  3.100 / 55.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'Sample_video_fps.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.20.100\n",
      "    comment         : Create videos with https://clipchamp.com/en/video-editor - free online video editor, video compressor, video converter.\n",
      "  Duration: 00:59:29.50, start: 0.000000, bitrate: 780 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1920x1080, 775 kb/s, 2 fps, 2 tbr, 16384 tbn, 4 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 2 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, image2, to './images/output_fps%04d.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    comment         : Create videos with https://clipchamp.com/en/video-editor - free online video editor, video compressor, video converter.\n",
      "    encoder         : Lavf58.20.100\n",
      "    Stream #0:0(und): Video: png, rgb24, 1920x1080, q=2-31, 200 kb/s, 1 fps, 1 tbn, 1 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc58.35.100 png\n",
      "frame= 3570 fps= 17 q=-0.0 Lsize=N/A time=00:59:30.00 bitrate=N/A speed=16.9x    \n",
      "video:6151747kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i Sample_video_fps.mp4 -vf fps=1 ./images/output_fps%04d.png\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f361ef-9bc0-4fec-8a34-37d67358fba6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# From Bard ---- Sure, here is a code that can be used to correct perspective distortion in an image using OpenCV:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada3c55e-664f-404b-86e4-e2d817feb86a",
   "metadata": {},
   "source": [
    "### Please note that this code is only for images -- other way could be to convert everything to images \n",
    "\n",
    "https://theailearner.com/tag/cv2-getperspectivetransform/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e57205-59a2-4899-83e0-758ded854f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f671b85-ecc0-457c-80b8-577ac8fa97b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD THE LOOPING CODE FOR IMAGES IN THE FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de375550-4ef4-47f4-b888-fd2fcfed00f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(815, 1441, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(\"warehouse_container_image_out.jpg\")\n",
    "print(image.shape)\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find the four corners of the image\n",
    "# If the corners were not found, exit the program\n",
    "\n",
    "### Define the corners agains which we are going to Correct prespective  \n",
    "\n",
    "pt_A = [41, 1000]\n",
    "pt_B = [10, 1200]\n",
    "pt_C = [500, 371]\n",
    "pt_D = [600, 136]\n",
    "\n",
    "# Here, I have used L2 norm. You can use L1 also.\n",
    "width_AD = np.sqrt(((pt_A[0] - pt_D[0]) ** 2) + ((pt_A[1] - pt_D[1]) ** 2))\n",
    "width_BC = np.sqrt(((pt_B[0] - pt_C[0]) ** 2) + ((pt_B[1] - pt_C[1]) ** 2))\n",
    "maxWidth = max(int(width_AD), int(width_BC))\n",
    " \n",
    " \n",
    "height_AB = np.sqrt(((pt_A[0] - pt_B[0]) ** 2) + ((pt_A[1] - pt_B[1]) ** 2))\n",
    "height_CD = np.sqrt(((pt_C[0] - pt_D[0]) ** 2) + ((pt_C[1] - pt_D[1]) ** 2))\n",
    "maxHeight = max(int(height_AB), int(height_CD))\n",
    "\n",
    "\n",
    "input_pts = np.float32([pt_A, pt_B, pt_C, pt_D])\n",
    "output_pts = np.float32([[0, 0],\n",
    "                        [0, maxHeight - 1],\n",
    "                        [maxWidth - 1, maxHeight - 1],\n",
    "                        [maxWidth - 1, 0]])\n",
    "###\n",
    "    \n",
    "# Calculate the homography matrix\n",
    "# homography = cv2.getPerspectiveTransform(corners[0], corners[1], corners[2])\n",
    "M = cv2.getPerspectiveTransform(input_pts,output_pts)\n",
    "\n",
    "\n",
    "# Transform the image\n",
    "# warped_image = cv2.warpPerspective(image, homography)\n",
    "\n",
    "out = cv2.warpPerspective(image,M,(maxWidth, maxHeight),flags=cv2.INTER_LINEAR)\n",
    "\n",
    "# Save the image\n",
    "cv2.imwrite(\"warehouse_warped_image.jpg\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db05d60d-25c3-4dff-a46c-cd93f8d10847",
   "metadata": {},
   "source": [
    "# Upload all the videos back to the GCS Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "351f0094-5296-4e65-b597-d0c00b546543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./output_fps000.mp4 [Content-Type=video/mp4]...\n",
      "Copying file://./output_fps001.mp4 [Content-Type=video/mp4]...                  \n",
      "Copying file://./output_fps002.mp4 [Content-Type=video/mp4]...                  \n",
      "Copying file://./output_fps003.mp4 [Content-Type=video/mp4]...                  \n",
      "| [4 files][226.1 MiB/226.1 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://./output_fps004.mp4 [Content-Type=video/mp4]...\n",
      "Copying file://./output_fps005.mp4 [Content-Type=video/mp4]...                  \n",
      "- [6 files][332.0 MiB/332.0 MiB]                                                \n",
      "Operation completed over 6 objects/332.0 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp ./images/output_fps* gs://my-project-0004-bucket02/experiments/  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e03de3-f6fd-41f6-b4f1-b23ea887af59",
   "metadata": {},
   "source": [
    "# Last Step is now to go to your Vertex AI console and download all the pre-processed data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81d8cb4-c31f-462e-9ae0-c6a65e8db735",
   "metadata": {},
   "source": [
    "## Prediction Code (only Run when you have End point Active condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdcc4bee-54ec-4685-86f0-a97373166611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.gapic.schema import predict\n",
    "\n",
    "\n",
    "def predict_image_classification_sample(\n",
    "    project: str,\n",
    "    endpoint_id: str,\n",
    "    filename: str,\n",
    "    location: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "):\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "    with open(filename, \"rb\") as f:\n",
    "        file_content = f.read()\n",
    "\n",
    "    # The format of each instance should conform to the deployed model's prediction input schema.\n",
    "    encoded_content = base64.b64encode(file_content).decode(\"utf-8\")\n",
    "    instance = predict.instance.ImageClassificationPredictionInstance(\n",
    "        content=encoded_content,\n",
    "    ).to_value()\n",
    "    instances = [instance]\n",
    "    # See gs://google-cloud-aiplatform/schema/predict/params/image_classification_1.0.0.yaml for the format of the parameters.\n",
    "    parameters = predict.params.ImageClassificationPredictionParams(\n",
    "        confidence_threshold=0.5, max_predictions=5,\n",
    "    ).to_value()\n",
    "    endpoint = client.endpoint_path(\n",
    "        project=project, location=location, endpoint=endpoint_id\n",
    "    )\n",
    "    response = client.predict(\n",
    "        endpoint=endpoint, instances=instances, parameters=parameters\n",
    "    )\n",
    "    print(\"response\")\n",
    "    print(\" deployed_model_id:\", response.deployed_model_id)\n",
    "    # See gs://google-cloud-aiplatform/schema/predict/prediction/image_classification_1.0.0.yaml for the format of the predictions.\n",
    "    predictions = response.predictions\n",
    "    for prediction in predictions:\n",
    "        print(\" prediction:\", dict(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "736d9b04-8718-4b5a-8b40-bbc8e122173b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response\n",
      " deployed_model_id: 8737682566494027776\n",
      " prediction: {'ids': ['893267985416847360'], 'displayNames': ['pneumonia'], 'confidences': [0.980921566]}\n"
     ]
    }
   ],
   "source": [
    "predict_image_classification_sample(\n",
    "    project=\"255766800726\",\n",
    "    endpoint_id=\"6227532704653508608\",\n",
    "    location=\"us-central1\",\n",
    "    filename=\"./warehouse_warped_image.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351ca6a0-d17a-4ab6-aeb6-02ad57b532b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7df967d8-d71d-4825-b9c3-e82d5e06e993",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Add code to write back to BQ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "226aba62-a5cf-4a43-a29f-e20dbac9356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE TO CREATE CHARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0678ad89-5753-4d9f-928c-386ef07b5028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
